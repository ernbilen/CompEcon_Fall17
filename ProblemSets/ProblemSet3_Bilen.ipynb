{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set \\#3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eren Bilen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "from scipy.optimize import minimize\n",
    "import scipy.stats as stats\n",
    "import statsmodels.formula.api as sm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_stata('PS3_data.dta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data and defining variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dropping NaN observations\n",
    "dataset = dataset.dropna(how='any', subset=['hannhrs', 'hlabinc','hyrsed','hrace'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Choosing only male heads\n",
    "dataset = dataset[dataset.hsex == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dropping individuals who worked 0 hours\n",
    "dataset = dataset[dataset.hannhrs!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining hourly wage\n",
    "dataset['hourlywage'] = dataset.hlabinc / dataset.hannhrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Choosing the age group\n",
    "dataset = dataset[(dataset.age>=25) & (dataset.age<=60)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Choosing individuals who earn more than $7 per hour\n",
    "dataset = dataset[dataset.hourlywage>7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Taking log of hourly wage\n",
    "dataset['loghourlywage'] = np.log(dataset.hourlywage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining race dummies\n",
    "dataset['white'] = (dataset['hrace'] == 1).astype(int)\n",
    "dataset['black'] = (dataset['hrace'] == 2).astype(int)\n",
    "dataset['hispanic'] = (dataset['hrace'] == 5).astype(int)\n",
    "dataset['other'] = ((dataset['hrace'] == 3) | (dataset['hrace']==4) | (dataset['hrace']==6) | (dataset['hrace']==7)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Also note that there are no Hispanic individuals in the data hence this \n",
    "# variable will be disregarded so that the data matrix X remains non-singular.\n",
    "dataset['hispanic'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating dataframes for each year\n",
    "dataset1971 = dataset[dataset.year == 1971]\n",
    "dataset1980 = dataset[dataset.year == 1980]\n",
    "dataset1990 = dataset[dataset.year == 1990]\n",
    "dataset2000 = dataset[dataset.year == 2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For 1971"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "b1 = np.array(dataset1971['hyrsed']).astype('float')\n",
    "b2 = np.array(dataset1971['black']).astype('float')\n",
    "b3 = np.array(dataset1971['hispanic']).astype('float')\n",
    "b4 = np.array(dataset1971['other']).astype('float')\n",
    "b5 = np.array(dataset1971['age']).astype('float')\n",
    "y = np.array(dataset1971['loghourlywage']).astype('float')\n",
    "\n",
    "# Creating matrix X, which will be useful soon\n",
    "\n",
    "nrow = b1.shape[0]\n",
    "intercept = np.ones((nrow,1))\n",
    "X=numpy.column_stack((intercept,b1,b2,b4,b5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Likelihood for 1971"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function that returns the negative log likelihood where \"parameters\" is a list for initial parameter values\n",
    "\n",
    "def LL(parameters):\n",
    "    \n",
    "    beta0 = parameters[0]\n",
    "    beta1 = parameters[1]\n",
    "    beta2 = parameters[2]\n",
    "    beta4 = parameters[3]\n",
    "    beta5 = parameters[4]\n",
    "    sd = parameters[5]\n",
    "    \n",
    "    # Creating a Beta vector that consists of the coefficients\n",
    "    Beta = [beta0, beta1, beta2, beta4, beta5]\n",
    "\n",
    "    # Calculating the predicted values using initial guesses for coefficients\n",
    "    yPred = np.dot(X, Beta)\n",
    "\n",
    "    # Calculating the negative log-likelihood assuming the values are normally distributed around the mean (yPred)\n",
    "    # and standard deviation, sd\n",
    "    neglogLik = -np.sum(stats.norm.logpdf(y, loc=yPred, scale=sd))\n",
    "\n",
    "    return(neglogLik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is a list for our initial parameter guesses (beta0, beta1, beta2, beta4, beta5, sd)    \n",
    "initGuess = [.1, .1, .1, .1, .1, .1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run the minimization process\n",
    "results1971 = minimize(LL, initGuess, method='Nelder-Mead', tol = 1e-12, options={'maxiter': 5000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient estimates for 1971:  [ 1.5509638   0.06687878 -0.16388756  0.03068778  0.01439146  0.41009898]\n"
     ]
    }
   ],
   "source": [
    "# Results\n",
    "print(\"Coefficient estimates for 1971: \", results1971.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the coefficients that maximize the log likelihood function. The order of the output is \n",
    "\n",
    "[$a, b_{educ}, b_{black}, b_{other}, b_{age}, sd$]\n",
    "\n",
    "As will be demonstrated below, these coefficients are almost identical to the OLS coefficients. More information on the optimization process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " final_simplex: (array([[ 1.5509638 ,  0.06687878, -0.16388756,  0.03068778,  0.01439146,\n",
       "         0.41009898],\n",
       "       [ 1.5509638 ,  0.06687878, -0.16388756,  0.03068778,  0.01439146,\n",
       "         0.41009898],\n",
       "       [ 1.5509638 ,  0.06687878, -0.16388756,  0.03068778,  0.01439146,\n",
       "         0.41009898],\n",
       "       [ 1.5509638 ,  0.06687878, -0.16388756,  0.03068778,  0.01439146,\n",
       "         0.41009898],\n",
       "       [ 1.5509638 ,  0.06687878, -0.16388756,  0.03068778,  0.01439146,\n",
       "         0.41009898],\n",
       "       [ 1.5509638 ,  0.06687878, -0.16388756,  0.03068778,  0.01439146,\n",
       "         0.41009898],\n",
       "       [ 1.5509638 ,  0.06687878, -0.16388756,  0.03068778,  0.01439146,\n",
       "         0.41009898]]), array([ 728.06286706,  728.06286706,  728.06286706,  728.06286706,\n",
       "        728.06286706,  728.06286706,  728.06286706]))\n",
       "           fun: 728.06286706384549\n",
       "       message: 'Optimization terminated successfully.'\n",
       "          nfev: 1708\n",
       "           nit: 1033\n",
       "        status: 0\n",
       "       success: True\n",
       "             x: array([ 1.5509638 ,  0.06687878, -0.16388756,  0.03068778,  0.01439146,\n",
       "        0.41009898])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results1971"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Checking work using linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept    1.550964e+00\n",
      "b1           6.687878e-02\n",
      "b2          -1.638876e-01\n",
      "b3           2.938373e-17\n",
      "b4           3.068777e-02\n",
      "b5           1.439146e-02\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "OLSresults1971 = sm.ols(formula=\"y ~ b1 + b2 + b3 + b4 + b5\", data=dataset1971).fit()\n",
    "print(OLSresults1971.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These coefficients are almost identical to the coefficients we get from MLE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternatively, we could run OLS manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.55096381,  0.06687878, -0.16388756,  0.03068777,  0.01439146])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLSresults_manual = np.dot(np.linalg.inv(np.dot(X.T,X)),np.dot(X.T,y))\n",
    "OLSresults_manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We get the same coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE for 1980"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient estimates for 1980:  [ 1.61308833  0.06755585 -0.10273614  0.01351126  0.01269854  0.44924262]\n"
     ]
    }
   ],
   "source": [
    "b1 = np.array(dataset1980['hyrsed']).astype('float')\n",
    "b2 = np.array(dataset1980['black']).astype('float')\n",
    "b3 = np.array(dataset1980['hispanic']).astype('float')\n",
    "b4 = np.array(dataset1980['other']).astype('float')\n",
    "b5 = np.array(dataset1980['age']).astype('float')\n",
    "y = np.array(dataset1980['loghourlywage']).astype('float')\n",
    "\n",
    "nrow = b1.shape[0]\n",
    "intercept = np.ones((nrow,1))\n",
    "X=numpy.column_stack((intercept,b1,b2,b4,b5))\n",
    "\n",
    "# Run the minimization process\n",
    "results1980 = minimize(LL, initGuess, method='Nelder-Mead', tol = 1e-12, options={'maxiter': 5000})\n",
    "\n",
    "# Results\n",
    "print(\"Coefficient estimates for 1980: \", results1980.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE for 1990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient estimates for 1990:  [ 1.11858497  0.09755808 -0.17202431 -0.05971251  0.0134656   0.48359944]\n"
     ]
    }
   ],
   "source": [
    "b1 = np.array(dataset1990['hyrsed']).astype('float')\n",
    "b2 = np.array(dataset1990['black']).astype('float')\n",
    "b3 = np.array(dataset1990['hispanic']).astype('float')\n",
    "b4 = np.array(dataset1990['other']).astype('float')\n",
    "b5 = np.array(dataset1990['age']).astype('float')\n",
    "y = np.array(dataset1990['loghourlywage']).astype('float')\n",
    "\n",
    "nrow = b1.shape[0]\n",
    "intercept = np.ones((nrow,1))\n",
    "X=numpy.column_stack((intercept,b1,b2,b4,b5))\n",
    "\n",
    "# Run the minimization process\n",
    "results1990 = minimize(LL, initGuess, method='Nelder-Mead', tol = 1e-12, options={'maxiter': 5000})\n",
    "\n",
    "# Results\n",
    "print(\"Coefficient estimates for 1990: \", results1990.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE for 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient estimates for 2000:  [ 1.16169082  0.10915436 -0.24604485 -0.06073246  0.01099353  0.53955729]\n"
     ]
    }
   ],
   "source": [
    "b1 = np.array(dataset2000['hyrsed']).astype('float')\n",
    "b2 = np.array(dataset2000['black']).astype('float')\n",
    "b3 = np.array(dataset2000['hispanic']).astype('float')\n",
    "b4 = np.array(dataset2000['other']).astype('float')\n",
    "b5 = np.array(dataset2000['age']).astype('float')\n",
    "y = np.array(dataset2000['loghourlywage']).astype('float')\n",
    "\n",
    "nrow = b1.shape[0]\n",
    "intercept = np.ones((nrow,1))\n",
    "X=numpy.column_stack((intercept,b1,b2,b4,b5))\n",
    "\n",
    "# Run the minimization process\n",
    "results2000 = minimize(LL, initGuess, method='Nelder-Mead', tol = 1e-12, options={'maxiter': 5000})\n",
    "\n",
    "# Results\n",
    "print(\"Coefficient estimates for 2000: \", results2000.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient estimates for 1971:  [ 1.5509638   0.06687878 -0.16388756  0.03068778  0.01439146  0.41009898]\n",
      "Coefficient estimates for 1980:  [ 1.61308833  0.06755585 -0.10273614  0.01351126  0.01269854  0.44924262]\n",
      "Coefficient estimates for 1990:  [ 1.11858497  0.09755808 -0.17202431 -0.05971251  0.0134656   0.48359944]\n",
      "Coefficient estimates for 2000:  [ 1.16169082  0.10915436 -0.24604485 -0.06073246  0.01099353  0.53955729]\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefficient estimates for 1971: \", results1971.x)\n",
    "print(\"Coefficient estimates for 1980: \", results1980.x)\n",
    "print(\"Coefficient estimates for 1990: \", results1990.x)\n",
    "print(\"Coefficient estimates for 2000: \", results2000.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, the order of the output is\n",
    "\n",
    "[$a, b_{educ}, b_{black}, b_{other}, b_{age}, sd$]\n",
    "\n",
    "We can see from the second column that, the coefficient estimate on education was about 0.066 in 1971. This would translate to an interpretation that, per additional year in education results in a 6.6% increase in hourly wage for an individual. The magnitude of this coefficient was about the same in 1980. Yet, in 1990, the magnitide goes up to 0.0975. Now, an additional year in education translates to a 9.75% increase in wage. The magnitude further increases to 10.9% in 2000. All in all, we see from this analysis that there is a positive association between education and wages. The magnitude of this association is higher in 1990-2000 period than it is for the 1971-1980 period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
